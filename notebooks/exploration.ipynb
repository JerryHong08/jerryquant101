{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "\n",
    "# df = pd.read_csv(\"../data/raw/us_stocks_sip/minute_aggs_v1/2025/08/2025-08-11.csv\")\n",
    "# df = df[df['ticker'] =='AAPL']\n",
    "stock_path = \"../data/lake/us_stocks_sip/minute_aggs_v1/2025/08/2025-08-08.parquet\"\n",
    "\n",
    "df = pl.read_parquet(stock_path).filter(pl.col(\"ticker\") == 'AAPL')\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(df.count())\n",
    "# 计算一日的vprice\n",
    "vprice_day = (df['volume'] * df['close']).sum() / df['volume'].sum()\n",
    "\n",
    "# print(\"收盘价Close:\", df.iloc[-1]['close'])\n",
    "print(\"一日的vprice:\", vprice_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1192ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "mode = widgets.Dropdown(\n",
    "    options=['backtest', 'live'],\n",
    "    value='backtest',\n",
    "    description='Mode:',\n",
    ")\n",
    "\n",
    "prefix = widgets.Text(\n",
    "    value='demo',\n",
    "    description='Prefix:',\n",
    ")\n",
    "\n",
    "display(mode, prefix)\n",
    "\n",
    "def run_strategy(m, p):\n",
    "    print(f\"运行模式: {m}, 前缀: {p}\")\n",
    "\n",
    "widgets.interactive(run_strategy, m=mode, p=prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ffa498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import polars as pl\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 数据路径（7月份所有 parquet 文件）\n",
    "# valid columns: [\"ticker\", \"volume\", \"open\", \"close\", \"high\", \"low\", \"window_start\", \"transactions\"]\n",
    "data_dir = \"../data/lake/us_stocks_sip/minute_aggs_v1/2025/07/*.parquet\"\n",
    "\n",
    "lf = (\n",
    "    pl.scan_parquet(data_dir)\n",
    "    .filter(pl.col(\"ticker\") == \"AAPL\")\n",
    "    .with_columns(\n",
    "        pl.from_epoch(pl.col(\"window_start\"), time_unit='ns')\n",
    "        # .dt.convert_time_zone(\"America/New_York\")\n",
    "        .alias('datetime')\n",
    "    )\n",
    ")\n",
    "\n",
    "df_all = lf.collect(engine='streaming')\n",
    "\n",
    "# 计算整月的成交量加权价格（VWAP）\n",
    "vprice_month = (df_all[\"volume\"] * df_all[\"close\"]).sum() / df_all[\"volume\"].sum()\n",
    "print(f\"\\n2025-07 VWAP: {vprice_month}\")\n",
    "\n",
    "\n",
    "# 使用Polars检查周末数据\n",
    "print(\"检查周末数据...\")\n",
    "week_data = df_all.filter(\n",
    "    (pl.col(\"datetime\") >= pl.datetime(2025, 7, 5)) & \n",
    "    (pl.col(\"datetime\") <= pl.datetime(2025, 7, 6, 23, 59, 59))\n",
    ")\n",
    "print(f\"2025-07-05到2025-07-06的数据行数: {week_data.height}\")\n",
    "\n",
    "# 更详细的日期检查\n",
    "print(\"\\n详细的日期检查:\")\n",
    "dates = ['2025-07-04', '2025-07-05', '2025-07-06', '2025-07-07']\n",
    "for date_str in dates:\n",
    "    year, month, day = map(int, date_str.split('-'))\n",
    "    start_datetime = pl.datetime(year, month, day)\n",
    "    end_datetime = pl.datetime(year, month, day, 23, 59, 59)\n",
    "    \n",
    "    date_data = df_all.filter(\n",
    "        (pl.col(\"datetime\") >= start_datetime) & \n",
    "        (pl.col(\"datetime\") <= end_datetime)\n",
    "    )\n",
    "    \n",
    "    # 获取星期几\n",
    "    weekday_num = datetime(year, month, day).weekday()  # 0=Monday, 6=Sunday\n",
    "    weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    weekday = weekdays[weekday_num]\n",
    "    \n",
    "    print(f\"{date_str} ({weekday}): {date_data.height} 行数据\")\n",
    "\n",
    "# 使用Polars检查星期几的分布\n",
    "print(\"\\n按星期几统计数据量:\")\n",
    "df_with_weekday = df_all.with_columns(\n",
    "    pl.col(\"datetime\").dt.strftime(\"%A\").alias(\"weekday\")\n",
    ")\n",
    "weekday_counts = df_with_weekday.group_by(\"weekday\").agg(pl.len().alias(\"count\")).sort(\"count\", descending=True)\n",
    "print(weekday_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74900d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use yfinance to double check splits discrepancy\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "ticker ='ENVX'\n",
    "\n",
    "df = yf.download(ticker,period='10y',actions=True)\n",
    "df= pd.DataFrame(df)\n",
    "with pd.option_context('display.max_rows', 50, \n",
    "                       'display.max_columns', 20, \n",
    "                       'display.max_colwidth', 100,\n",
    "                       'display.width', None,           # 不限制总宽度\n",
    "                       'display.expand_frame_repr', False):  # 不要换行显示\n",
    "    df = df[df['Stock Splits'] > 0].dropna()\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecab876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_split_adjustments(df: pl.DataFrame, splits: pl.DataFrame, price_columns: list = None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    通用的分拆调整函数\n",
    "    \n",
    "    Args:\n",
    "        df: 包含价格数据的DataFrame，必须包含 'ticker' 和 'datetime' 列\n",
    "        splits: 分拆数据DataFrame，包含 'ticker', 'execution_date', 'split_from', 'split_to' 列\n",
    "        price_columns: 需要调整的价格列名列表，默认为 ['open', 'close', 'high', 'low']\n",
    "    \n",
    "    Returns:\n",
    "        调整后的DataFrame\n",
    "    \"\"\"\n",
    "    if price_columns is None:\n",
    "        price_columns = ['open', 'close', 'high', 'low']\n",
    "    \n",
    "    # 确保日期格式正确\n",
    "    splits_processed = splits.with_columns([\n",
    "        pl.col('execution_date').str.to_date().alias('split_date'),\n",
    "        (pl.col('split_from') / pl.col('split_to')).alias('split_ratio')\n",
    "    ])\n",
    "    \n",
    "    # 为每个ticker计算累计分拆比率\n",
    "    result_df = df.clone()\n",
    "    \n",
    "    for ticker in df['ticker'].unique():\n",
    "        ticker_splits = splits_processed.filter(pl.col('ticker') == ticker).sort('split_date')\n",
    "        ticker_data = df.filter(pl.col('ticker') == ticker).sort('datetime')\n",
    "        \n",
    "        if ticker_splits.height == 0:\n",
    "            continue\n",
    "            \n",
    "        # 为每行数据计算需要应用的累计分拆比率\n",
    "        ticker_data = ticker_data.with_columns([\n",
    "            pl.col('datetime').dt.date().alias('data_date')\n",
    "        ])\n",
    "        \n",
    "        # 使用join_asof进行时间匹配，获取每个数据点之后发生的所有分拆\n",
    "        adjusted_data = ticker_data.clone()\n",
    "        \n",
    "        for price_col in price_columns:\n",
    "            if price_col in ticker_data.columns:\n",
    "                # 计算该日期之后的所有分拆的累计比率\n",
    "                cumulative_ratios = []\n",
    "                \n",
    "                for row in ticker_data.iter_rows(named=True):\n",
    "                    data_date = row['data_date']\n",
    "                    # 获取该日期之后的所有分拆\n",
    "                    future_splits = ticker_splits.filter(pl.col('split_date') > data_date)\n",
    "                    \n",
    "                    # 计算累计分拆比率\n",
    "                    if future_splits.height > 0:\n",
    "                        cumulative_ratio = future_splits['split_ratio'].product()\n",
    "                    else:\n",
    "                        cumulative_ratio = 1.0\n",
    "                    \n",
    "                    cumulative_ratios.append(cumulative_ratio)\n",
    "                \n",
    "                # 应用分拆调整\n",
    "                adjusted_data = adjusted_data.with_columns([\n",
    "                    (pl.col(price_col) * pl.Series(cumulative_ratios)).alias(price_col)\n",
    "                ])\n",
    "        \n",
    "        # 调整成交量（分拆时成交量按相反比例调整）\n",
    "        if 'volume' in ticker_data.columns:\n",
    "            volume_ratios = []\n",
    "            for row in ticker_data.iter_rows(named=True):\n",
    "                data_date = row['data_date']\n",
    "                future_splits = ticker_splits.filter(pl.col('split_date') > data_date)\n",
    "                \n",
    "                if future_splits.height > 0:\n",
    "                    # 成交量按分拆比率的倒数调整\n",
    "                    volume_ratio = (1 / future_splits['split_ratio']).product()\n",
    "                else:\n",
    "                    volume_ratio = 1.0\n",
    "                \n",
    "                volume_ratios.append(volume_ratio)\n",
    "            \n",
    "            adjusted_data = adjusted_data.with_columns([\n",
    "                (pl.col('volume') * pl.Series(volume_ratios)).alias('volume')\n",
    "            ])\n",
    "        \n",
    "        # 更新结果\n",
    "        result_df = result_df.filter(pl.col('ticker') != ticker).vstack(\n",
    "            adjusted_data.drop('data_date')\n",
    "        )\n",
    "    \n",
    "    return result_df.sort(['ticker', 'datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6769e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all_tickers_file: /mnt/blackdisk/quant_data/polygon_data/raw/us_stocks_sip/us_all_tickers/all_tickers_20250904.parquet\n"
     ]
    }
   ],
   "source": [
    "from quant101.core_2.config import all_tickers_dir\n",
    "import os\n",
    "import glob\n",
    "\n",
    "end_date = \"2025-08-01\"\n",
    "\n",
    "file_date = end_date.replace('-', '')\n",
    "all_tickers_file = os.path.join(all_tickers_dir, f'all_tickers_{file_date}.parquet')\n",
    "\n",
    "if not os.path.exists(all_tickers_file):\n",
    "    # Find all matching parquet files\n",
    "    files = glob.glob(os.path.join(all_tickers_dir, 'all_tickers_*.parquet'))\n",
    "    # Extract date part and sort by closest, prefer larger or equal dates\n",
    "    def extract_date(f):\n",
    "        try:\n",
    "            return int(os.path.basename(f).split('_')[-1].replace('.parquet', ''))\n",
    "        except Exception:\n",
    "            return float('inf')\n",
    "    file_dates = [(f, extract_date(f)) for f in files]\n",
    "    file_dates = [fd for fd in file_dates if fd[1] != float('inf')]\n",
    "    if file_dates:\n",
    "        # Sort by (abs diff, prefer larger date)\n",
    "        file_dates.sort(key=lambda x: (abs(x[1] - int(file_date)), x[1] < int(file_date)))\n",
    "        all_tickers_file = file_dates[0][0]\n",
    "    else:\n",
    "        all_tickers_file = None\n",
    "        \n",
    "print(f\"Using all_tickers_file: {all_tickers_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed322d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每个ticker的信号持续期详情:\n",
      "shape: (8, 6)\n",
      "┌────────┬──────────────┬─────────────────────┬─────────────────────┬──────────────┬───────────────┐\n",
      "│ ticker ┆ signal_group ┆ start_date          ┆ end_date            ┆ signal_count ┆ duration_days │\n",
      "│ ---    ┆ ---          ┆ ---                 ┆ ---                 ┆ ---          ┆ ---           │\n",
      "│ str    ┆ u32          ┆ datetime[μs]        ┆ datetime[μs]        ┆ u32          ┆ i64           │\n",
      "╞════════╪══════════════╪═════════════════════╪═════════════════════╪══════════════╪═══════════════╡\n",
      "│ A      ┆ 1            ┆ 2023-01-05 00:00:00 ┆ 2023-01-06 00:00:00 ┆ 2            ┆ 2             │\n",
      "│ A      ┆ 2            ┆ 2024-05-03 00:00:00 ┆ 2024-05-03 00:00:00 ┆ 1            ┆ 1             │\n",
      "│ A      ┆ 3            ┆ 2024-10-15 00:00:00 ┆ 2024-10-15 00:00:00 ┆ 1            ┆ 1             │\n",
      "│ AA     ┆ 1            ┆ 2023-05-22 00:00:00 ┆ 2023-05-22 00:00:00 ┆ 1            ┆ 1             │\n",
      "│ AA     ┆ 2            ┆ 2025-06-02 00:00:00 ┆ 2025-06-02 00:00:00 ┆ 1            ┆ 1             │\n",
      "│ AA     ┆ 3            ┆ 2025-06-25 00:00:00 ┆ 2025-06-27 00:00:00 ┆ 3            ┆ 3             │\n",
      "│ AACB   ┆ 1            ┆ 2025-06-26 00:00:00 ┆ 2025-06-27 00:00:00 ┆ 2            ┆ 2             │\n",
      "│ AACB   ┆ 2            ┆ 2025-06-30 00:00:00 ┆ 2025-07-03 00:00:00 ┆ 4            ┆ 4             │\n",
      "└────────┴──────────────┴─────────────────────┴─────────────────────┴──────────────┴───────────────┘\n",
      "\n",
      "每个ticker的平均持续天数:\n",
      "shape: (3, 4)\n",
      "┌────────┬───────────────────┬──────────────────────┬───────────────────┐\n",
      "│ ticker ┆ avg_duration_days ┆ signal_periods_count ┆ total_signal_days │\n",
      "│ ---    ┆ ---               ┆ ---                  ┆ ---               │\n",
      "│ str    ┆ f64               ┆ u32                  ┆ i64               │\n",
      "╞════════╪═══════════════════╪══════════════════════╪═══════════════════╡\n",
      "│ AACB   ┆ 3.0               ┆ 2                    ┆ 6                 │\n",
      "│ AA     ┆ 1.666667          ┆ 3                    ┆ 5                 │\n",
      "│ A      ┆ 1.333333          ┆ 3                    ┆ 4                 │\n",
      "└────────┴───────────────────┴──────────────────────┴───────────────────┘\n",
      "\n",
      "整体统计:\n",
      "平均信号持续天数: 2.00 天\n",
      "中位数信号持续天数: 1.67 天\n",
      "最长平均持续天数: 3.00 天\n",
      "最短平均持续天数: 1.33 天\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keys/aggregates are not partitionable: running default HASH AGGREGATION\n",
      "keys/aggregates are not partitionable: running default HASH AGGREGATION\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from quant101.utils.compute import calculate_signal_duration\n",
    "import datetime as dt\n",
    "\n",
    "# 定义每个 ticker 的时间序列\n",
    "ticker_data = {\n",
    "    \"A\": [\n",
    "        dt.datetime(2023,1,5),\n",
    "        dt.datetime(2023,1,6),\n",
    "        dt.datetime(2024,5,3),\n",
    "        dt.datetime(2024,10,15),\n",
    "    ],\n",
    "    \"AA\": [\n",
    "        dt.datetime(2023,5,22),\n",
    "        dt.datetime(2025,6,2),\n",
    "        dt.datetime(2025,6,25),\n",
    "        dt.datetime(2025,6,26),\n",
    "        dt.datetime(2025,6,27),\n",
    "    ],\n",
    "    \"AACB\": [\n",
    "        dt.datetime(2025,6,26),\n",
    "        dt.datetime(2025,6,27),\n",
    "        dt.datetime(2025,6,30),\n",
    "        dt.datetime(2025,7,1),\n",
    "        dt.datetime(2025,7,2),\n",
    "        dt.datetime(2025,7,3),\n",
    "    ],\n",
    "}\n",
    "\n",
    "# 每个 ticker 转成一个 DataFrame，然后拼接\n",
    "dfs = []\n",
    "for ticker, dates in ticker_data.items():\n",
    "    df = pl.DataFrame(\n",
    "        {\n",
    "            \"timestamps\": dates,\n",
    "            \"ticker\": [ticker] * len(dates),\n",
    "            \"signal\": [1] * len(dates),\n",
    "        }\n",
    "    )\n",
    "    dfs.append(df)\n",
    "\n",
    "signals = pl.concat(dfs)\n",
    "\n",
    "with pl.Config(tbl_cols=20, tbl_rows=500, tbl_width_chars=1000, verbose=True):\n",
    "    # print(signals)\n",
    "\n",
    "    signal_durations, avg_durations = calculate_signal_duration(signals)\n",
    "    print(\"每个ticker的信号持续期详情:\")\n",
    "    print(signal_durations.head(20))\n",
    "    print(\"\\n每个ticker的平均持续天数:\")\n",
    "    print(avg_durations.head(20))\n",
    "                \n",
    "    # 也可以查看整体统计\n",
    "    print(f\"\\n整体统计:\")\n",
    "    print(f\"平均信号持续天数: {avg_durations['avg_duration_days'].mean():.2f} 天\")\n",
    "    print(f\"中位数信号持续天数: {avg_durations['avg_duration_days'].median():.2f} 天\")\n",
    "    print(f\"最长平均持续天数: {avg_durations['avg_duration_days'].max():.2f} 天\")\n",
    "    print(f\"最短平均持续天数: {avg_durations['avg_duration_days'].min():.2f} 天\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant101-rQ2o9wWd-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
