{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "\n",
    "# df = pd.read_csv(\"../data/raw/us_stocks_sip/minute_aggs_v1/2025/08/2025-08-11.csv\")\n",
    "# df = df[df['ticker'] =='AAPL']\n",
    "stock_path = \"../data/lake/us_stocks_sip/minute_aggs_v1/2025/08/2025-08-08.parquet\"\n",
    "\n",
    "df = pl.read_parquet(stock_path).filter(pl.col(\"ticker\") == 'AAPL')\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(df.count())\n",
    "# 计算一日的vprice\n",
    "vprice_day = (df['volume'] * df['close']).sum() / df['volume'].sum()\n",
    "\n",
    "# print(\"收盘价Close:\", df.iloc[-1]['close'])\n",
    "print(\"一日的vprice:\", vprice_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1192ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "mode = widgets.Dropdown(\n",
    "    options=['backtest', 'live'],\n",
    "    value='backtest',\n",
    "    description='Mode:',\n",
    ")\n",
    "\n",
    "prefix = widgets.Text(\n",
    "    value='demo',\n",
    "    description='Prefix:',\n",
    ")\n",
    "\n",
    "display(mode, prefix)\n",
    "\n",
    "def run_strategy(m, p):\n",
    "    print(f\"运行模式: {m}, 前缀: {p}\")\n",
    "\n",
    "widgets.interactive(run_strategy, m=mode, p=prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ffa498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-07 VWAP: 211.3413595311783\n",
      "检查周末数据...\n",
      "2025-07-05到2025-07-06的数据行数: 0\n",
      "\n",
      "详细的日期检查:\n",
      "2025-07-04 (Friday): 0 行数据\n",
      "2025-07-05 (Saturday): 0 行数据\n",
      "2025-07-06 (Sunday): 0 行数据\n",
      "2025-07-07 (Monday): 828 行数据\n",
      "\n",
      "按星期几统计数据量:\n",
      "shape: (5, 2)\n",
      "┌───────────┬───────┐\n",
      "│ weekday   ┆ count │\n",
      "│ ---       ┆ ---   │\n",
      "│ str       ┆ u32   │\n",
      "╞═══════════╪═══════╡\n",
      "│ Tuesday   ┆ 3925  │\n",
      "│ Wednesday ┆ 3803  │\n",
      "│ Thursday  ┆ 3583  │\n",
      "│ Monday    ┆ 3071  │\n",
      "│ Friday    ┆ 2107  │\n",
      "└───────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import polars as pl\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 数据路径（7月份所有 parquet 文件）\n",
    "# valid columns: [\"ticker\", \"volume\", \"open\", \"close\", \"high\", \"low\", \"window_start\", \"transactions\"]\n",
    "data_dir = \"../data/lake/us_stocks_sip/minute_aggs_v1/2025/07/*.parquet\"\n",
    "\n",
    "lf = (\n",
    "    pl.scan_parquet(data_dir)\n",
    "    .filter(pl.col(\"ticker\") == \"AAPL\")\n",
    "    .with_columns(\n",
    "        pl.from_epoch(pl.col(\"window_start\"), time_unit='ns')\n",
    "        # .dt.convert_time_zone(\"America/New_York\")\n",
    "        .alias('datetime')\n",
    "    )\n",
    ")\n",
    "\n",
    "df_all = lf.collect(engine='streaming')\n",
    "\n",
    "# 计算整月的成交量加权价格（VWAP）\n",
    "vprice_month = (df_all[\"volume\"] * df_all[\"close\"]).sum() / df_all[\"volume\"].sum()\n",
    "print(f\"\\n2025-07 VWAP: {vprice_month}\")\n",
    "\n",
    "\n",
    "# 使用Polars检查周末数据\n",
    "print(\"检查周末数据...\")\n",
    "week_data = df_all.filter(\n",
    "    (pl.col(\"datetime\") >= pl.datetime(2025, 7, 5)) & \n",
    "    (pl.col(\"datetime\") <= pl.datetime(2025, 7, 6, 23, 59, 59))\n",
    ")\n",
    "print(f\"2025-07-05到2025-07-06的数据行数: {week_data.height}\")\n",
    "\n",
    "# 更详细的日期检查\n",
    "print(\"\\n详细的日期检查:\")\n",
    "dates = ['2025-07-04', '2025-07-05', '2025-07-06', '2025-07-07']\n",
    "for date_str in dates:\n",
    "    year, month, day = map(int, date_str.split('-'))\n",
    "    start_datetime = pl.datetime(year, month, day)\n",
    "    end_datetime = pl.datetime(year, month, day, 23, 59, 59)\n",
    "    \n",
    "    date_data = df_all.filter(\n",
    "        (pl.col(\"datetime\") >= start_datetime) & \n",
    "        (pl.col(\"datetime\") <= end_datetime)\n",
    "    )\n",
    "    \n",
    "    # 获取星期几\n",
    "    weekday_num = datetime(year, month, day).weekday()  # 0=Monday, 6=Sunday\n",
    "    weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    weekday = weekdays[weekday_num]\n",
    "    \n",
    "    print(f\"{date_str} ({weekday}): {date_data.height} 行数据\")\n",
    "\n",
    "# 使用Polars检查星期几的分布\n",
    "print(\"\\n按星期几统计数据量:\")\n",
    "df_with_weekday = df_all.with_columns(\n",
    "    pl.col(\"datetime\").dt.strftime(\"%A\").alias(\"weekday\")\n",
    ")\n",
    "weekday_counts = df_with_weekday.group_by(\"weekday\").agg(pl.len().alias(\"count\")).sort(\"count\", descending=True)\n",
    "print(weekday_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74900d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use yfinance to double check splits discrepancy\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "ticker ='ENVX'\n",
    "\n",
    "df = yf.download(ticker,period='10y',actions=True)\n",
    "df= pd.DataFrame(df)\n",
    "with pd.option_context('display.max_rows', 50, \n",
    "                       'display.max_columns', 20, \n",
    "                       'display.max_colwidth', 100,\n",
    "                       'display.width', None,           # 不限制总宽度\n",
    "                       'display.expand_frame_repr', False):  # 不要换行显示\n",
    "    df = df[df['Stock Splits'] > 0].dropna()\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecab876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_split_adjustments(df: pl.DataFrame, splits: pl.DataFrame, price_columns: list = None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    通用的分拆调整函数\n",
    "    \n",
    "    Args:\n",
    "        df: 包含价格数据的DataFrame，必须包含 'ticker' 和 'datetime' 列\n",
    "        splits: 分拆数据DataFrame，包含 'ticker', 'execution_date', 'split_from', 'split_to' 列\n",
    "        price_columns: 需要调整的价格列名列表，默认为 ['open', 'close', 'high', 'low']\n",
    "    \n",
    "    Returns:\n",
    "        调整后的DataFrame\n",
    "    \"\"\"\n",
    "    if price_columns is None:\n",
    "        price_columns = ['open', 'close', 'high', 'low']\n",
    "    \n",
    "    # 确保日期格式正确\n",
    "    splits_processed = splits.with_columns([\n",
    "        pl.col('execution_date').str.to_date().alias('split_date'),\n",
    "        (pl.col('split_from') / pl.col('split_to')).alias('split_ratio')\n",
    "    ])\n",
    "    \n",
    "    # 为每个ticker计算累计分拆比率\n",
    "    result_df = df.clone()\n",
    "    \n",
    "    for ticker in df['ticker'].unique():\n",
    "        ticker_splits = splits_processed.filter(pl.col('ticker') == ticker).sort('split_date')\n",
    "        ticker_data = df.filter(pl.col('ticker') == ticker).sort('datetime')\n",
    "        \n",
    "        if ticker_splits.height == 0:\n",
    "            continue\n",
    "            \n",
    "        # 为每行数据计算需要应用的累计分拆比率\n",
    "        ticker_data = ticker_data.with_columns([\n",
    "            pl.col('datetime').dt.date().alias('data_date')\n",
    "        ])\n",
    "        \n",
    "        # 使用join_asof进行时间匹配，获取每个数据点之后发生的所有分拆\n",
    "        adjusted_data = ticker_data.clone()\n",
    "        \n",
    "        for price_col in price_columns:\n",
    "            if price_col in ticker_data.columns:\n",
    "                # 计算该日期之后的所有分拆的累计比率\n",
    "                cumulative_ratios = []\n",
    "                \n",
    "                for row in ticker_data.iter_rows(named=True):\n",
    "                    data_date = row['data_date']\n",
    "                    # 获取该日期之后的所有分拆\n",
    "                    future_splits = ticker_splits.filter(pl.col('split_date') > data_date)\n",
    "                    \n",
    "                    # 计算累计分拆比率\n",
    "                    if future_splits.height > 0:\n",
    "                        cumulative_ratio = future_splits['split_ratio'].product()\n",
    "                    else:\n",
    "                        cumulative_ratio = 1.0\n",
    "                    \n",
    "                    cumulative_ratios.append(cumulative_ratio)\n",
    "                \n",
    "                # 应用分拆调整\n",
    "                adjusted_data = adjusted_data.with_columns([\n",
    "                    (pl.col(price_col) * pl.Series(cumulative_ratios)).alias(price_col)\n",
    "                ])\n",
    "        \n",
    "        # 调整成交量（分拆时成交量按相反比例调整）\n",
    "        if 'volume' in ticker_data.columns:\n",
    "            volume_ratios = []\n",
    "            for row in ticker_data.iter_rows(named=True):\n",
    "                data_date = row['data_date']\n",
    "                future_splits = ticker_splits.filter(pl.col('split_date') > data_date)\n",
    "                \n",
    "                if future_splits.height > 0:\n",
    "                    # 成交量按分拆比率的倒数调整\n",
    "                    volume_ratio = (1 / future_splits['split_ratio']).product()\n",
    "                else:\n",
    "                    volume_ratio = 1.0\n",
    "                \n",
    "                volume_ratios.append(volume_ratio)\n",
    "            \n",
    "            adjusted_data = adjusted_data.with_columns([\n",
    "                (pl.col('volume') * pl.Series(volume_ratios)).alias('volume')\n",
    "            ])\n",
    "        \n",
    "        # 更新结果\n",
    "        result_df = result_df.filter(pl.col('ticker') != ticker).vstack(\n",
    "            adjusted_data.drop('data_date')\n",
    "        )\n",
    "    \n",
    "    return result_df.sort(['ticker', 'datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6769e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7402/2331543957.py:99: UserWarning: Sortedness of columns cannot be checked when 'by' groups provided\n",
      "  df_adj = lf_adj.collect()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:shape: (1, 9)\n",
      "┌────────┬────────┬──────┬───────┬───┬──────┬───────────────────┬──────────────┬───────────────────┐\n",
      "│ ticker ┆ volume ┆ open ┆ close ┆ … ┆ low  ┆ window_start      ┆ transactions ┆ datetime          │\n",
      "│ ---    ┆ ---    ┆ ---  ┆ ---   ┆   ┆ ---  ┆ ---               ┆ ---          ┆ ---               │\n",
      "│ str    ┆ u32    ┆ f32  ┆ f32   ┆   ┆ f32  ┆ i64               ┆ u32          ┆ datetime[ns,      │\n",
      "│        ┆        ┆      ┆       ┆   ┆      ┆                   ┆              ┆ America/New_York] │\n",
      "╞════════╪════════╪══════╪═══════╪═══╪══════╪═══════════════════╪══════════════╪═══════════════════╡\n",
      "│ BIVI   ┆ 1027   ┆ 0.92 ┆ 0.92  ┆ … ┆ 0.92 ┆ 17513676000000000 ┆ 3            ┆ 2025-07-01        │\n",
      "│        ┆        ┆      ┆       ┆   ┆      ┆ 00                ┆              ┆ 07:00:00 EDT      │\n",
      "└────────┴────────┴──────┴───────┴───┴──────┴───────────────────┴──────────────┴───────────────────┘\n",
      "before tail:shape: (1, 9)\n",
      "┌────────┬────────┬──────┬───────┬───┬─────┬────────────────────┬──────────────┬───────────────────┐\n",
      "│ ticker ┆ volume ┆ open ┆ close ┆ … ┆ low ┆ window_start       ┆ transactions ┆ datetime          │\n",
      "│ ---    ┆ ---    ┆ ---  ┆ ---   ┆   ┆ --- ┆ ---                ┆ ---          ┆ ---               │\n",
      "│ str    ┆ u32    ┆ f32  ┆ f32   ┆   ┆ f32 ┆ i64                ┆ u32          ┆ datetime[ns,      │\n",
      "│        ┆        ┆      ┆       ┆   ┆     ┆                    ┆              ┆ America/New_York] │\n",
      "╞════════╪════════╪══════╪═══════╪═══╪═════╪════════════════════╪══════════════╪═══════════════════╡\n",
      "│ BIVI   ┆ 200    ┆ 6.0  ┆ 6.0   ┆ … ┆ 6.0 ┆ 175399716000000000 ┆ 1            ┆ 2025-07-31        │\n",
      "│        ┆        ┆      ┆       ┆   ┆     ┆ 0                  ┆              ┆ 17:26:00 EDT      │\n",
      "└────────┴────────┴──────┴───────┴───┴─────┴────────────────────┴──────────────┴───────────────────┘\n",
      "after:shape: (1, 8)\n",
      "┌────────┬────────────┬──────────┬──────────┬─────────┬───────────┬──────────────┬─────────────────┐\n",
      "│ ticker ┆ volume_adj ┆ open_adj ┆ high_adj ┆ low_adj ┆ close_adj ┆ transactions ┆ datetime        │\n",
      "│ ---    ┆ ---        ┆ ---      ┆ ---      ┆ ---     ┆ ---       ┆ ---          ┆ ---             │\n",
      "│ str    ┆ i64        ┆ f64      ┆ f64      ┆ f64     ┆ f64       ┆ u32          ┆ datetime[ns,    │\n",
      "│        ┆            ┆          ┆          ┆         ┆           ┆              ┆ America/New_Yor │\n",
      "│        ┆            ┆          ┆          ┆         ┆           ┆              ┆ k]              │\n",
      "╞════════╪════════════╪══════════╪══════════╪═════════╪═══════════╪══════════════╪═════════════════╡\n",
      "│ BIVI   ┆ 103        ┆ 9.2      ┆ 9.2      ┆ 9.2     ┆ 9.2       ┆ 3            ┆ 2025-07-01      │\n",
      "│        ┆            ┆          ┆          ┆         ┆           ┆              ┆ 07:00:00 EDT    │\n",
      "└────────┴────────────┴──────────┴──────────┴─────────┴───────────┴──────────────┴─────────────────┘\n",
      "after tail:shape: (1, 8)\n",
      "┌────────┬────────────┬──────────┬──────────┬─────────┬───────────┬──────────────┬─────────────────┐\n",
      "│ ticker ┆ volume_adj ┆ open_adj ┆ high_adj ┆ low_adj ┆ close_adj ┆ transactions ┆ datetime        │\n",
      "│ ---    ┆ ---        ┆ ---      ┆ ---      ┆ ---     ┆ ---       ┆ ---          ┆ ---             │\n",
      "│ str    ┆ i64        ┆ f64      ┆ f64      ┆ f64     ┆ f64       ┆ u32          ┆ datetime[ns,    │\n",
      "│        ┆            ┆          ┆          ┆         ┆           ┆              ┆ America/New_Yor │\n",
      "│        ┆            ┆          ┆          ┆         ┆           ┆              ┆ k]              │\n",
      "╞════════╪════════════╪══════════╪══════════╪═════════╪═══════════╪══════════════╪═════════════════╡\n",
      "│ BIVI   ┆ 200        ┆ 6.0      ┆ 6.0      ┆ 6.0     ┆ 6.0       ┆ 1            ┆ 2025-07-31      │\n",
      "│        ┆            ┆          ┆          ┆         ┆           ┆              ┆ 17:26:00 EDT    │\n",
      "└────────┴────────────┴──────────┴──────────┴─────────┴───────────┴──────────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import seolpyo_mplchart as mc\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\", message=\".*Font family.*not found.*\")\n",
    "matplotlib.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "# 数据路径（7月份所有 parquet 文件）\n",
    "# valid columns: [\"ticker\", \"volume\", \"open\", \"close\", \"high\", \"low\", \"window_start\", \"transactions\"]\n",
    "data_dir = \"../data/lake/us_stocks_sip/minute_aggs_v1/2025/07/*.parquet\"\n",
    "\n",
    "# splits data\n",
    "splits_dir = \"../data/raw/us_stocks_sip/splits/splits.parquet\"\n",
    "splits_error_dir = \"../data/raw/us_stocks_sip/splits/splits_error.parquet\"\n",
    "\n",
    "splits_original = pl.read_parquet(splits_dir)\n",
    "splits_errors = pl.read_parquet(splits_error_dir)\n",
    "\n",
    "splits = splits_original.filter(~pl.col(\"id\").is_in(splits_errors[\"id\"].implode()))\n",
    "\n",
    "# print(splits.sort(['execution_date']).filter(pl.col('ticker') == 'BIVI'))\n",
    "\n",
    "lf = (\n",
    "    pl.scan_parquet(data_dir).with_columns(\n",
    "        pl.from_epoch(pl.col(\"window_start\"), time_unit=\"ns\")\n",
    "        .dt.convert_time_zone(\"America/New_York\")\n",
    "        .alias(\"datetime\")\n",
    "    )\n",
    ")\n",
    "\n",
    "def splits_adjust(lf, splits, price_decimals:int = 4):\n",
    "    # 获取数据范围\n",
    "    date_min = lf.select(pl.col(\"datetime\").min()).collect()[0, 0]\n",
    "    date_max = lf.select(pl.col(\"datetime\").max()).collect()[0, 0]\n",
    "    \n",
    "    tickers = lf.select(pl.col(\"ticker\").unique()).collect().to_series(0).to_list()\n",
    "\n",
    "    splits_filtered = (\n",
    "        splits.filter(\n",
    "            (pl.col('ticker').is_in(tickers)) &\n",
    "            (pl.col('execution_date').str.to_date().is_between(date_min - pl.duration(days=1), date_max + pl.duration(days=1)))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if splits_filtered.is_empty():\n",
    "        lf = lf.with_columns([\n",
    "            pl.col(\"open\").alias(\"open_adj\"),\n",
    "            pl.col(\"high\").alias(\"high_adj\"),\n",
    "            pl.col(\"low\").alias(\"low_adj\"),\n",
    "            pl.col(\"close\").alias(\"close_adj\"),\n",
    "            pl.col(\"volume\").alias(\"volume_adj\"),\n",
    "        ])\n",
    "    else:\n",
    "        splits_processed = (\n",
    "            splits_filtered.with_columns(\n",
    "                [\n",
    "                    pl.col('execution_date').str.to_date().alias('split_date'),\n",
    "                    (pl.col('split_from') / pl.col('split_to')).alias('split_ratio')\n",
    "                ]\n",
    "            )\n",
    "            .select(['ticker', 'split_date', 'split_ratio'])\n",
    "        )\n",
    "        \n",
    "        splits_with_factor = (\n",
    "            splits_processed\n",
    "            .sort(['ticker', 'split_date'], descending=[False, True])\n",
    "            .with_columns(pl.col('split_ratio').cum_prod().over('ticker').alias('cumulative_split_ratio'))\n",
    "            .sort(['ticker', 'split_date'])\n",
    "        )\n",
    "        \n",
    "        # 由于 Polars join_asof 需要对齐日期类型，可以先添加辅助列\n",
    "        lf_adj = (\n",
    "            lf.with_columns(\n",
    "                pl.col(\"datetime\").dt.date().alias(\"date_only\")\n",
    "            )\n",
    "            .join_asof(\n",
    "                splits_with_factor.lazy(),\n",
    "                left_on=\"date_only\",\n",
    "                right_on=\"split_date\",\n",
    "                by=\"ticker\",\n",
    "                strategy=\"forward\",\n",
    "            )\n",
    "            .with_columns(pl.col('cumulative_split_ratio').fill_null(1.0).alias('factor'))\n",
    "            .with_columns([\n",
    "                (pl.col(\"open\") * pl.col(\"factor\")).round(price_decimals).alias(\"open_adj\"),\n",
    "                (pl.col(\"high\") * pl.col(\"factor\")).round(price_decimals).alias(\"high_adj\"),\n",
    "                (pl.col(\"low\") * pl.col(\"factor\")).round(price_decimals).alias(\"low_adj\"),\n",
    "                (pl.col(\"close\") * pl.col(\"factor\")).round(price_decimals).alias(\"close_adj\"),\n",
    "                (pl.col(\"volume\") / pl.col(\"factor\")).round(0).cast(pl.Int64).alias(\"volume_adj\"),\n",
    "            ])\n",
    "            .drop(\"date_only\")\n",
    "        )\n",
    "\n",
    "    return lf_adj\n",
    "\n",
    "lf_adj = splits_adjust(lf, splits, price_decimals=4)\n",
    "df_adj = lf_adj.collect()\n",
    "\n",
    "df_test = lf.filter(pl.col(\"ticker\") == \"BIVI\").collect()\n",
    "df_test_adj = df_adj.filter(pl.col(\"ticker\") == \"BIVI\").select(['ticker', 'volume_adj', 'open_adj', 'high_adj', 'low_adj', 'close_adj', 'transactions', 'datetime']).sort(['datetime'])\n",
    "# -----------later test------------\n",
    "print(f\"before:{df_test.head(1)}\")\n",
    "print(f\"before tail:{df_test.tail(1)}\")\n",
    "\n",
    "print(f\"after:{df_test_adj.head(1)}\")\n",
    "print(f\"after tail:{df_test_adj.tail(1)}\")\n",
    "\n",
    "\n",
    "#!!!!!!!!!remind to restart the jupyter kernel other than your memory could explode!!!!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant101-rQ2o9wWd-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
