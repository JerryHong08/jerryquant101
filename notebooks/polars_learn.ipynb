{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da5ce69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>birthdate</th><th>weight</th><th>height</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Alice Archer&quot;</td><td>&quot;1997-01-10&quot;</td><td>57.9</td><td>1.56</td></tr><tr><td>&quot;Ben Brown&quot;</td><td>&quot;1985-02-15&quot;</td><td>72.5</td><td>1.77</td></tr><tr><td>&quot;Chloe Cooper&quot;</td><td>&quot;1983-03-22&quot;</td><td>53.6</td><td>1.65</td></tr><tr><td>&quot;Daniel Donovan&quot;</td><td>&quot;1981-04-30&quot;</td><td>83.1</td><td>1.75</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 4)\n",
       "┌────────────────┬────────────┬────────┬────────┐\n",
       "│ name           ┆ birthdate  ┆ weight ┆ height │\n",
       "│ ---            ┆ ---        ┆ ---    ┆ ---    │\n",
       "│ str            ┆ str        ┆ f64    ┆ f64    │\n",
       "╞════════════════╪════════════╪════════╪════════╡\n",
       "│ Alice Archer   ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   │\n",
       "│ Ben Brown      ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
       "│ Chloe Cooper   ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   │\n",
       "│ Daniel Donovan ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   │\n",
       "└────────────────┴────────────┴────────┴────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import os\n",
    "from quant101.core_2.config import data_dir\n",
    "test_file_dir = os.path.join(data_dir, \"lake/test/polars.csv\")\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice Archer\", \"Ben Brown\", \"Chloe Cooper\", \"Daniel Donovan\"],\n",
    "        # \"birthdate\": [\n",
    "        #     dt.date(1997, 1, 10),\n",
    "        #     dt.date(1985, 2, 15),\n",
    "        #     dt.date(1983, 3, 22),\n",
    "        #     dt.date(1981, 4, 30),\n",
    "        # ],\n",
    "        \"birthdate\": [\n",
    "            '1997-01-10',\n",
    "            '1985-02-15',\n",
    "            '1983-03-22',\n",
    "            '1981-04-30',\n",
    "        ],\n",
    "        \"weight\": [57.9, 72.5, 53.6, 83.1],  # (kg)\n",
    "        \"height\": [1.56, 1.77, 1.65, 1.75],  # (m)\n",
    "    }\n",
    ")\n",
    "\n",
    "df.cast({\"weight\": pl.Float32, \"birthdate\": pl.Date, \"height\": pl.Float32})\n",
    "# df\n",
    "\n",
    "# df.write_csv(test_file_dir)\n",
    "\n",
    "# df_csv = pl.read_csv(test_file_dir, try_parse_dates=True)\n",
    "\n",
    "# print(df_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877df66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌────────┬────────────┬────────────┬───────┬───────────┬───────────────────┬───────────────────┐\n",
      "│ ticker ┆ vwap       ┆ last_close ┆ ratio ┆ vwap_diff ┆ ratio_stability_1 ┆ ratio_stability_2 │\n",
      "│ ---    ┆ ---        ┆ ---        ┆ ---   ┆ ---       ┆ ---               ┆ ---               │\n",
      "│ str    ┆ f64        ┆ f32        ┆ f64   ┆ f64       ┆ f64               ┆ f32               │\n",
      "╞════════╪════════════╪════════════╪═══════╪═══════════╪═══════════════════╪═══════════════════╡\n",
      "│ ESGR   ┆ 337.910004 ┆ 337.910004 ┆ 1.0   ┆ 0.0       ┆ 0.0               ┆ 0.0               │\n",
      "│ FIG    ┆ 115.5      ┆ 115.5      ┆ 1.0   ┆ 0.0       ┆ 0.0               ┆ 0.0               │\n",
      "│ ZXIET  ┆ 100.0      ┆ 100.0      ┆ 1.0   ┆ 0.0       ┆ 0.0               ┆ 0.0               │\n",
      "│ LBDAV  ┆ 91.860001  ┆ 91.860001  ┆ 1.0   ┆ 0.0       ┆ 0.0               ┆ 0.0               │\n",
      "│ AEBIV  ┆ 83.260002  ┆ 83.260002  ┆ 1.0   ┆ 0.0       ┆ 0.0               ┆ 0.0               │\n",
      "└────────┴────────────┴────────────┴───────┴───────────┴───────────────────┴───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from quant101.core_2.data_loader import data_dir_calculate\n",
    "import os\n",
    "\n",
    "lake_file_paths = data_dir_calculate(asset='us_stock_sip', data_type='minute_aggs_v1', start_date='2025-07-01', end_date='2025-07-31', lake=True)\n",
    "\n",
    "lf = pl.scan_parquet(\n",
    "        lake_file_paths,\n",
    "    )\n",
    "\n",
    "# 计算 VWAP (每个 ticker)\n",
    "vwap = (\n",
    "    lf.filter(pl.col(\"volume\") > 0)\n",
    "        .group_by(\"ticker\")\n",
    "        .agg((pl.col(\"close\") * pl.col(\"volume\")).sum() / pl.col(\"volume\").sum())\n",
    "        .rename({\"close\": \"vwap\"})\n",
    ")\n",
    "\n",
    "# print(vwap.collect().sort('ticker').head())\n",
    "\n",
    "\n",
    "# 找到每个 ticker 当月最后的 close\n",
    "last_close = (\n",
    "    lf.sort(\"window_start\")\n",
    "      .group_by(\"ticker\")\n",
    "      .tail(1)\n",
    "      .select([\"ticker\", \"close\"])\n",
    "      .rename({\"close\": \"last_close\"})\n",
    ")\n",
    "\n",
    "# print(last_close.collect().sort('ticker').head())\n",
    "\n",
    "# 合并结果，计算比率\n",
    "result = (\n",
    "    vwap.join(last_close, on=\"ticker\")\n",
    "        .with_columns(\n",
    "            (\n",
    "                pl.col(\"last_close\") / pl.col(\"vwap\")).alias(\"ratio\"),\n",
    "                (pl.col(\"last_close\") - pl.col(\"vwap\")).abs().alias(\"vwap_diff\"),\n",
    "                ((pl.col(\"last_close\") - pl.col(\"vwap\")) / pl.col(\"vwap\")).abs().alias(\"ratio_stability_1\"),\n",
    "                abs((pl.col(\"last_close\") - pl.col(\"vwap\")) / pl.col(\"vwap\")).cast(pl.Float32).alias(\"ratio_stability_2\")\n",
    "             )\n",
    "        .sort(\"ratio_stability_1\",'last_close', descending=[False, True])\n",
    ")\n",
    "\n",
    "print(result.collect().head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c45efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b472df3436a410ba828326e996478c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker      vwap  last_close      ratio\n",
      "0    GVH  0.133029        5.56  41.795326\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "data_dir = \"../data/lake/us_stocks_sip/minute_aggs_v1/2025/07/*.parquet\"\n",
    "con = duckdb.connect()\n",
    "\n",
    "query = f\"\"\"\n",
    "WITH vwap AS (\n",
    "    SELECT \n",
    "        ticker,\n",
    "        SUM(close * volume)::DOUBLE / NULLIF(SUM(volume),0) AS vwap\n",
    "    FROM '{data_dir}'\n",
    "    GROUP BY ticker\n",
    "),\n",
    "last_close AS (\n",
    "    SELECT DISTINCT ON (ticker)\n",
    "        ticker, close AS last_close\n",
    "    FROM '{data_dir}'\n",
    "    ORDER BY ticker, window_start DESC\n",
    ")\n",
    "SELECT \n",
    "    vwap.ticker,\n",
    "    vwap.vwap,\n",
    "    last_close.last_close,\n",
    "    last_close.last_close / vwap.vwap AS ratio\n",
    "FROM vwap\n",
    "JOIN last_close USING (ticker)\n",
    "ORDER BY ratio DESC\n",
    "LIMIT 1;\n",
    "\"\"\"\n",
    "\n",
    "result = con.sql(query).df()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4343bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (45, 5)\n",
      "┌─────────────────────┬────────────────────────────────┬───────────────────┬───────────────────┬────────────────────────────────┐\n",
      "│ index               ┆ open                           ┆ break_start       ┆ break_end         ┆ close                          │\n",
      "│ ---                 ┆ ---                            ┆ ---               ┆ ---               ┆ ---                            │\n",
      "│ datetime[ns]        ┆ datetime[ns, America/New_York] ┆ datetime[ns, UTC] ┆ datetime[ns, UTC] ┆ datetime[ns, America/New_York] │\n",
      "╞═════════════════════╪════════════════════════════════╪═══════════════════╪═══════════════════╪════════════════════════════════╡\n",
      "│ 2005-11-25 00:00:00 ┆ 2005-11-25 09:30:00 EST        ┆ null              ┆ null              ┆ 2005-11-25 13:00:00 EST        │\n",
      "│ 2006-07-03 00:00:00 ┆ 2006-07-03 09:30:00 EDT        ┆ null              ┆ null              ┆ 2006-07-03 13:00:00 EDT        │\n",
      "│ 2006-11-24 00:00:00 ┆ 2006-11-24 09:30:00 EST        ┆ null              ┆ null              ┆ 2006-11-24 13:00:00 EST        │\n",
      "│ 2007-07-03 00:00:00 ┆ 2007-07-03 09:30:00 EDT        ┆ null              ┆ null              ┆ 2007-07-03 13:00:00 EDT        │\n",
      "│ 2007-11-23 00:00:00 ┆ 2007-11-23 09:30:00 EST        ┆ null              ┆ null              ┆ 2007-11-23 13:00:00 EST        │\n",
      "│ …                   ┆ …                              ┆ …                 ┆ …                 ┆ …                              │\n",
      "│ 2024-11-29 00:00:00 ┆ 2024-11-29 09:30:00 EST        ┆ null              ┆ null              ┆ 2024-11-29 13:00:00 EST        │\n",
      "│ 2024-12-24 00:00:00 ┆ 2024-12-24 09:30:00 EST        ┆ null              ┆ null              ┆ 2024-12-24 13:00:00 EST        │\n",
      "│ 2025-07-03 00:00:00 ┆ 2025-07-03 09:30:00 EDT        ┆ null              ┆ null              ┆ 2025-07-03 13:00:00 EDT        │\n",
      "│ 2025-11-28 00:00:00 ┆ 2025-11-28 09:30:00 EST        ┆ null              ┆ null              ┆ 2025-11-28 13:00:00 EST        │\n",
      "│ 2025-12-24 00:00:00 ┆ 2025-12-24 09:30:00 EST        ┆ null              ┆ null              ┆ 2025-12-24 13:00:00 EST        │\n",
      "└─────────────────────┴────────────────────────────────┴───────────────────┴───────────────────┴────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import exchange_calendars as xcals\n",
    "\n",
    "# 纽约证券交易所 (美国)\n",
    "xnys = xcals.get_calendar('XNYS')\n",
    "snys_schedule = xnys.schedule.loc['2005-01-01':'2025-12-31'] \n",
    "\n",
    "# 转换为 Polars DataFrame\n",
    "df_schedule = pl.from_pandas(snys_schedule.reset_index())\n",
    "\n",
    "df_schedule = df_schedule.with_columns([\n",
    "    pl.col('open').dt.convert_time_zone('America/New_York'),\n",
    "    pl.col('close').dt.convert_time_zone('America/New_York')\n",
    "])\n",
    "\n",
    "with pl.Config(tbl_cols=200, fmt_str_lengths=200, tbl_width_chars=3000, tbl_formatting=\"UTF8_FULL_CONDENSED\"):\n",
    "    df_schedule_filtered = df_schedule.filter(\n",
    "        pl.col('close').dt.hour() != 16\n",
    "    )\n",
    "    print(df_schedule_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb480a0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'data_dir_calculate' from 'quant101.core_2.config' (/home/jerryhong/code-projects/quant101/src/quant101/core_2/config.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpolars\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpl\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mquant101\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore_2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data_dir, data_dir_calculate\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Get the file paths\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'data_dir_calculate' from 'quant101.core_2.config' (/home/jerryhong/code-projects/quant101/src/quant101/core_2/config.py)"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from quant101.core_2.config import data_dir, data_dir_calculate\n",
    "import os\n",
    "\n",
    "# Get the file paths\n",
    "lake_file_paths = data_dir_calculate(\n",
    "    asset='us_stocks_sip', \n",
    "    data_type='day_aggs_v1', \n",
    "    start_date='2025-07-02',\n",
    "    end_date='2025-07-07',\n",
    "    lake=True\n",
    ")\n",
    "\n",
    "if not lake_file_paths:\n",
    "        raise ValueError(\n",
    "            f\"No data files found.\"\n",
    "        )\n",
    "\n",
    "tickers = 'UVXY'\n",
    "tickers = [t.strip().upper() for t in tickers.split(\",\")] if tickers else None\n",
    "if tickers:\n",
    "    lf = pl.scan_parquet(lake_file_paths).filter(pl.col('ticker').is_in(tickers))\n",
    "else:\n",
    "    lf = pl.scan_parquet(lake_file_paths)\n",
    "\n",
    "lf = lf.with_columns(\n",
    "    pl.from_epoch(pl.col('window_start'), time_unit='ns')\n",
    "    .dt.convert_time_zone('America/New_York')\n",
    "    .alias('timestamps')\n",
    "\n",
    ").sort('timestamps').collect()\n",
    "with pl.Config(tbl_cols=10):\n",
    "    print(lf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e818c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quant101.core_2.data_loader import data_loader\n",
    "import polars as pl\n",
    "from quant101.core_2.plotter import plot_candlestick\n",
    "\n",
    "tickers = ['NVDA']\n",
    "# tickers = None\n",
    "timeframe = \"1h\" # timeframe: '1m', '3m', '5m', '10m', '15m', '20m', '30m', '45m', '1h', '2h', '3h', '4h', '1d' 等\n",
    "asset = 'us_stocks_sip'\n",
    "data_type = ('day_aggs_v1' if timeframe == '1d' else 'minute_aggs_v1')\n",
    "start_date = \"2025-07-01\"\n",
    "end_date = \"2025-07-08\"\n",
    "full_hour = True\n",
    "\n",
    "lf_result = data_loader(\n",
    "        tickers=tickers, \n",
    "        timeframe=timeframe, \n",
    "        asset=asset, \n",
    "        data_type=data_type, \n",
    "        start_date=start_date, \n",
    "        end_date=end_date,\n",
    "        full_hour=full_hour\n",
    "    ).collect()\n",
    "\n",
    "print(lf_result.head())\n",
    "\n",
    "# plot_candlestick(lf_result.to_pandas(), ticker=tickers, timeframe=timeframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant101-rQ2o9wWd-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
